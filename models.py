from pydantic import BaseModel ,Field
from typing import  Literal


class ShouldRetrieve(BaseModel):
    """Pydantic model for retrieval decision with explanation"""
    decision: Literal["Yes", "No"] = Field(
        ..., 
        description="Whether external document retrieval is needed. 'Yes' if the query requires specific facts, recent information, or domain expertise not in the model's training data. 'No' if the query can be answered with general knowledge or reasoning."
    )
    explanation: str = Field(
        ..., 
        description="Clear reasoning for the retrieval decision, explaining what type of information is needed (if Yes) or why existing knowledge is sufficient (if No)."
    )

class RelevanceAssessment(BaseModel):
    """Pydantic model for document relevance assessment"""
    relevance: Literal["Relevant", "Irrelevant"] = Field(
        ..., 
        description="Whether the document content is relevant to answering the query. 'Relevant' if the document contains information that directly helps answer the question or complete the task. 'Irrelevant' if the document content is unrelated, tangential, or doesn't provide useful information for the given instruction."
    )


class SupportAssessment(BaseModel):
    """Pydantic model for assessing if generated response is supported by evidence"""
    support_level: Literal["Fully supported", "Partially supported", "No support"] = Field(
        ..., 
        description="Level of support between the generated response and evidence document. 'Fully supported' if all claims in the response are backed by the evidence. 'Partially supported' if some claims are supported but major information lacks evidence support. 'No support' if the response ignores, contradicts, or is unrelated to the evidence."
    )

class UtilityAssessment(BaseModel):
    """Pydantic model for assessing the utility/helpfulness of generated response"""
    utility_score: Literal[1, 2, 3, 4, 5] = Field(
        ..., 
        description="Utility rating from 1-5 based on how helpful and informative the response is. 5: Complete, highly detailed, and fully addresses the query. 4: Mostly fulfills the need with minor improvements possible. 3: Acceptable response but requires major additions to be complete. 2: Addresses main request but incomplete or not fully relevant. 1: Barely on-topic or completely irrelevant to the instruction."
    )

class RAGAnswer(BaseModel):
    """
    Output schema for a Retrieval-Augmented Generation (RAG) system.
    Represents the answer generated by the model based on the provided context.
    """
    answer: str = Field(
        ...,
        description="The answer generated by the model using the provided context. ")